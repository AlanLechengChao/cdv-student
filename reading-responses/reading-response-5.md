##Society of Quantified Individuals, the Burden and the Value
Of all the problems discussed in the reading and the podcasts, their starting point are all results from processes of quantifying individuals. One important aspect of quantifying is turning unmeasurable factors into fixed values. For instance, ethics. Measurements for ethics often fall into language forms, using adjectives like evil or kind, yet no quantifiable values are involved, as what is presented in the social credit system, public data records, and all sorts of digital representations of the self. However, these data could become troublesome to think of once they are recorded somewhere else without your ability to control over it. These data brings out more burden on the person as they socially become a part of the person, either it is they social credit value, the information accessible to the ClearView program. The burden evolves when the data might no longer fits the description of the person, or as it might be obstacles in the person's life.

Similar to the dang'an (档案) system in China, recording a person's public records is yet not new in the society. One important dilemma mentioned in the podcast is whether to keep criminal records of somebody's early life, since the existence of these records plants future biases to outsider's perspective of that person. Ethically, someone might not be intrinsically evil only because of the criminal records, yet in some cases lack of public records might lead to cases like policeman shooting a 12-year-old with a toy gun, as the policeman's previous unethical records has been overlooked. Hence, implementing *the right to be forgotten* could indeed be necessary yet it gives out a chance for those who would be considered ethically questionable to swipe their previous record and pretend themselves to be innocent. One possible solution to this problem is to have a committee that offer chances for individuals to implement *their right to be forgotten*, yet the committee should be deciding in what circumstances does the records could be hidden. Take the previous example, even though the policeman might intended to erase his previous records, being a **policeman** itself requires considering one's ethical situation more seriously, hence the records should not be hidden when the police office is hiring this person. On contrary, if the same person changes his career to jobs that do not consider criminal records to be critical, the records could be hidden. Yet this do not erase it dilemma nature, while more executions might be involved in this process.

Aside from the public records, which mostly falls into the control of legal systems, our general data of either social media accounts, even just our faces presented and captured in the public, would have a more complicated state of belonging. In China, we can clearly see the case of government agencies cooperating with major tech companies for the capture of personal data, and particularly facial recognition. While in other cases, we can see somebody making softwares like ClearView that might presented you some information about you that "you had never seen before". The advantage of these connectivity of databases is obvious, as police would be able to find criminals in **minutes**, just by glancing through a records of social media posts. And as Zoe had mentioned in the comment section of the [reading](https://docs.google.com/document/d/1yi5y8stuTh4f3sycR12NcNZr4_u-jAU0Zq5HV-3gqOA/edit), WeChat logs is right now accessible to law enforcement agencies as evidences that could be used in courts. While in the podcast the creators of ClearView obviously mentioned about selling these information to agencies other than law enforcement, and gaining the value from the quantified information of individuals. Will we still have the *right to be forgotten*? The mechanisms of protecting this right is missing, due to various ethically unclear questions. 
